{"cells":[{"cell_type":"markdown","id":"96513f51-f7c1-4b3d-b703-e758268e3efa","metadata":{},"source":["<p style=\"text-align:center\">\n","    <a href=\"https://skills.network\" target=\"_blank\">\n","    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\">\n","    </a>\n","</p>\n"]},{"cell_type":"markdown","id":"b0427b82-e4eb-4bdd-af07-881f7cd822b0","metadata":{},"source":["# Table of Contents\n","\n","<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n","\n","<font size = 3>\n","    \n","1. <a href=\"#item31\">Data Engineering</a> \n","2. <a href=\"#item31\">Data Engineering Process</a>  \n","3. <a href=\"#item32\">Working with different file formats</a> \n","4. <a href=\"#item33\">Data Analysis</a> \n","\n","</font>\n","</div>\n"]},{"cell_type":"markdown","id":"00e96b8e-1c12-4700-90b9-ff000d2fa079","metadata":{},"source":["# Data Engineering\n"]},{"cell_type":"markdown","id":"52a13a09-b554-4654-998e-175bcb3494d9","metadata":{},"source":["**Data engineering** is one of the most critical and foundational skills in any data scientist’s toolkit.\n"]},{"cell_type":"markdown","id":"8ce01e24-a0b1-44b3-b2b9-fea11f851781","metadata":{},"source":["# Data Engineering Process\n"]},{"cell_type":"markdown","id":"93215be9-d862-47bd-b1b2-bec1a2db8504","metadata":{},"source":["There are several steps in Data Engineering process.\n","\n","1. **Extract** - Data extraction is getting data from multiple sources. Ex. Data extraction from a website using Web scraping or gathering information from the data that are stored in different formats(JSON, CSV, XLSX etc.).\n","\n","2. **Transform** - Tarnsforming the data means removing the data that we don't need for further analysis and converting the data in the format that all the data from the multiple sources is in the same format.\n","\n","3. **Load** - Loading the data inside a data warehouse. Data warehouse essentially contains large volumes of data that are accessed to gather insights.\n"]},{"cell_type":"markdown","id":"104cca85-d1ce-49fe-826d-9cc8c47c36e3","metadata":{},"source":["# Working with different file formats\n"]},{"cell_type":"markdown","id":"f8d0837a-365b-42c3-b3e5-bc018f97a6ac","metadata":{},"source":["In the real-world, people rarely get neat tabular data. Thus, it is mandatory for any data scientist (or data engineer) to be aware of different file formats, common challenges in handling them and the best, most efficient ways to handle this data in real life. We have reviewed some of this content in other modules.\n"]},{"cell_type":"markdown","id":"941bb3f7-1ff0-4f7e-a58e-82364958442d","metadata":{},"source":["#### File Format\n"]},{"cell_type":"markdown","id":"4ca39ca0-ae7d-4a02-9655-ccbd506d0368","metadata":{},"source":["A file format is a standard way in which information is encoded for storage in a file. First, the file format specifies whether the file is a binary or ASCII file. Second, it shows how the information is organized. For example, the comma-separated values (CSV) file format stores tabular data in plain text.\n","\n","To identify a file format, you can usually look at the file extension to get an idea. For example, a file saved with name “Data” in “CSV” format will appear as “Data.csv”. By noticing the “.csv” extension, we can clearly identify that it is a “CSV” file and the data is stored in a tabular format.\n"]},{"cell_type":"markdown","id":"55add8a9-385e-4fe9-aba9-1b04c2dea0fe","metadata":{},"source":["There are various formats for a dataset, .csv, .json, .xlsx etc. The dataset can be stored in different places, on your local machine or sometimes online.\n","\n","**In this section, you will learn how to load a dataset into our Jupyter Notebook.**\n"]},{"cell_type":"markdown","id":"3fc9d147-61ba-40bd-846f-cfb05ca9c0dd","metadata":{},"source":["Now, we will look at some file formats and how to read them in Python:\n"]},{"cell_type":"markdown","id":"dc26dead-b2e8-4a6e-9a84-50d36aec10e3","metadata":{},"source":["# Comma-separated values (CSV) file format\n"]},{"cell_type":"markdown","id":"81451629-bcf1-4cfa-910c-41544bb7d34f","metadata":{},"source":["The **Comma-separated values** file format falls under a spreadsheet file format.\n","\n","In a spreadsheet file format, data is stored in cells. Each cell is organized in rows and columns. A column in the spreadsheet file can have different types. For example, a column can be of string type, a date type, or an integer type.\n","\n","Each line in CSV file represents an observation, or commonly called a record. Each record may contain one or more fields which are separated by a comma.\n"]},{"cell_type":"markdown","id":"420067ab-afc8-410d-a68e-ad7bd717c91f","metadata":{},"source":["## Reading data from CSV in Python\n"]},{"cell_type":"markdown","id":"8a14b25b-214c-4fe0-9948-63a2bcf23de0","metadata":{},"source":["The **Pandas** Library is a useful tool that enables us to read various datasets into a Pandas data frame\n","\n","Let us look at how to read a CSV file in Pandas Library.\n","\n","We use **pandas.read_csv()** function to read the csv file. In the parentheses, we put the file path along with a quotation mark as an argument, so that pandas will read the file into a data frame from that address. The file path can be either a URL or your local file address.\n"]},{"cell_type":"code","execution_count":1,"id":"2baa6861-927d-4cdc-80f5-05d76fa69cfd","metadata":{},"outputs":[],"source":["import pandas as pd"]},{"cell_type":"code","execution_count":2,"id":"fd648804-46a9-4196-8ee5-407e94f49689","metadata":{},"outputs":[],"source":["url ='https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0101EN-SkillsNetwork/labs/Module%205/data/addresses.csv'\n","df = pd.read_csv(url,header=None)"]},{"cell_type":"code","execution_count":5,"id":"9fda101f-031a-46f3-9ab1-9d753e3f9c69","metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>First Name</th>\n","      <th>Last Name</th>\n","      <th>Location</th>\n","      <th>City</th>\n","      <th>State</th>\n","      <th>Area Code</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>John</td>\n","      <td>Doe</td>\n","      <td>120 jefferson st.</td>\n","      <td>Riverside</td>\n","      <td>NJ</td>\n","      <td>8075</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Jack</td>\n","      <td>McGinnis</td>\n","      <td>220 hobo Av.</td>\n","      <td>Phila</td>\n","      <td>PA</td>\n","      <td>9119</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>John \"Da Man\"</td>\n","      <td>Repici</td>\n","      <td>120 Jefferson St.</td>\n","      <td>Riverside</td>\n","      <td>NJ</td>\n","      <td>8075</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Stephen</td>\n","      <td>Tyler</td>\n","      <td>7452 Terrace \"At the Plaza\" road</td>\n","      <td>SomeTown</td>\n","      <td>SD</td>\n","      <td>91234</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>NaN</td>\n","      <td>Blankman</td>\n","      <td>NaN</td>\n","      <td>SomeTown</td>\n","      <td>SD</td>\n","      <td>298</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Joan \"the bone\", Anne</td>\n","      <td>Jet</td>\n","      <td>9th, at Terrace plc</td>\n","      <td>Desert City</td>\n","      <td>CO</td>\n","      <td>123</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              First Name Last Name                         Location   \\\n","0                   John       Doe                 120 jefferson st.   \n","1                   Jack  McGinnis                      220 hobo Av.   \n","2          John \"Da Man\"    Repici                 120 Jefferson St.   \n","3                Stephen     Tyler  7452 Terrace \"At the Plaza\" road   \n","4                    NaN  Blankman                               NaN   \n","5  Joan \"the bone\", Anne       Jet               9th, at Terrace plc   \n","\n","          City State  Area Code  \n","0    Riverside    NJ       8075  \n","1        Phila    PA       9119  \n","2    Riverside    NJ       8075  \n","3     SomeTown    SD      91234  \n","4     SomeTown    SD        298  \n","5  Desert City    CO        123  "]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["df"]},{"cell_type":"markdown","id":"849f8cd1-4988-495d-924b-246f5248b4c8","metadata":{},"source":["#### Adding column name to the DataFrame\n","\n","We can add columns to an existing DataFrame using its **columns** attribute.\n"]},{"cell_type":"code","execution_count":4,"id":"09118a91-d442-4a0a-8ec4-bc5a8c13e27d","metadata":{},"outputs":[],"source":["df.columns =['First Name', 'Last Name', 'Location ', 'City','State','Area Code']"]},{"cell_type":"code","execution_count":6,"id":"19f2bb57-08b1-47cd-bf05-1170704e84dc","metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>First Name</th>\n","      <th>Last Name</th>\n","      <th>Location</th>\n","      <th>City</th>\n","      <th>State</th>\n","      <th>Area Code</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>John</td>\n","      <td>Doe</td>\n","      <td>120 jefferson st.</td>\n","      <td>Riverside</td>\n","      <td>NJ</td>\n","      <td>8075</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Jack</td>\n","      <td>McGinnis</td>\n","      <td>220 hobo Av.</td>\n","      <td>Phila</td>\n","      <td>PA</td>\n","      <td>9119</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>John \"Da Man\"</td>\n","      <td>Repici</td>\n","      <td>120 Jefferson St.</td>\n","      <td>Riverside</td>\n","      <td>NJ</td>\n","      <td>8075</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Stephen</td>\n","      <td>Tyler</td>\n","      <td>7452 Terrace \"At the Plaza\" road</td>\n","      <td>SomeTown</td>\n","      <td>SD</td>\n","      <td>91234</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>NaN</td>\n","      <td>Blankman</td>\n","      <td>NaN</td>\n","      <td>SomeTown</td>\n","      <td>SD</td>\n","      <td>298</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Joan \"the bone\", Anne</td>\n","      <td>Jet</td>\n","      <td>9th, at Terrace plc</td>\n","      <td>Desert City</td>\n","      <td>CO</td>\n","      <td>123</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              First Name Last Name                         Location   \\\n","0                   John       Doe                 120 jefferson st.   \n","1                   Jack  McGinnis                      220 hobo Av.   \n","2          John \"Da Man\"    Repici                 120 Jefferson St.   \n","3                Stephen     Tyler  7452 Terrace \"At the Plaza\" road   \n","4                    NaN  Blankman                               NaN   \n","5  Joan \"the bone\", Anne       Jet               9th, at Terrace plc   \n","\n","          City State  Area Code  \n","0    Riverside    NJ       8075  \n","1        Phila    PA       9119  \n","2    Riverside    NJ       8075  \n","3     SomeTown    SD      91234  \n","4     SomeTown    SD        298  \n","5  Desert City    CO        123  "]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["df"]},{"cell_type":"markdown","id":"e8fcce6b-5487-49d7-80ae-6fc559fa65ed","metadata":{},"source":["#### Selecting a single column\n","\n","To select the first column 'First Name', you can pass the column name as a string to the indexing operator.\n"]},{"cell_type":"code","execution_count":7,"id":"1450c746-c13e-4dd4-a1a9-0a2e10c6b7d9","metadata":{},"outputs":[{"data":{"text/plain":["0                     John\n","1                     Jack\n","2            John \"Da Man\"\n","3                  Stephen\n","4                      NaN\n","5    Joan \"the bone\", Anne\n","Name: First Name, dtype: object"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["df[\"First Name\"]"]},{"cell_type":"markdown","id":"b9c42de0-f4a9-463b-90bf-75fe4681a71d","metadata":{},"source":["#### Selecting multiple columns\n","\n","To select multiple columns, you can pass a list of column names to the indexing operator.\n"]},{"cell_type":"code","execution_count":8,"id":"5578c66c-9acb-4560-a9ee-b8cc0dbc3948","metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>First Name</th>\n","      <th>Last Name</th>\n","      <th>Location</th>\n","      <th>City</th>\n","      <th>State</th>\n","      <th>Area Code</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>John</td>\n","      <td>Doe</td>\n","      <td>120 jefferson st.</td>\n","      <td>Riverside</td>\n","      <td>NJ</td>\n","      <td>8075</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Jack</td>\n","      <td>McGinnis</td>\n","      <td>220 hobo Av.</td>\n","      <td>Phila</td>\n","      <td>PA</td>\n","      <td>9119</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>John \"Da Man\"</td>\n","      <td>Repici</td>\n","      <td>120 Jefferson St.</td>\n","      <td>Riverside</td>\n","      <td>NJ</td>\n","      <td>8075</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Stephen</td>\n","      <td>Tyler</td>\n","      <td>7452 Terrace \"At the Plaza\" road</td>\n","      <td>SomeTown</td>\n","      <td>SD</td>\n","      <td>91234</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>NaN</td>\n","      <td>Blankman</td>\n","      <td>NaN</td>\n","      <td>SomeTown</td>\n","      <td>SD</td>\n","      <td>298</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Joan \"the bone\", Anne</td>\n","      <td>Jet</td>\n","      <td>9th, at Terrace plc</td>\n","      <td>Desert City</td>\n","      <td>CO</td>\n","      <td>123</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              First Name Last Name                         Location   \\\n","0                   John       Doe                 120 jefferson st.   \n","1                   Jack  McGinnis                      220 hobo Av.   \n","2          John \"Da Man\"    Repici                 120 Jefferson St.   \n","3                Stephen     Tyler  7452 Terrace \"At the Plaza\" road   \n","4                    NaN  Blankman                               NaN   \n","5  Joan \"the bone\", Anne       Jet               9th, at Terrace plc   \n","\n","          City State  Area Code  \n","0    Riverside    NJ       8075  \n","1        Phila    PA       9119  \n","2    Riverside    NJ       8075  \n","3     SomeTown    SD      91234  \n","4     SomeTown    SD        298  \n","5  Desert City    CO        123  "]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["df = df[['First Name', 'Last Name', 'Location ', 'City','State','Area Code']]\n","df"]},{"cell_type":"markdown","id":"1b2ef1f4-86a7-48e2-bc5c-fe81ff6715d8","metadata":{},"source":["#### Selecting rows using .iloc and .loc\n","\n","Now, let's see how to use .loc for selecting rows from our DataFrame. \n","\n","**loc() : loc() is label based data selecting method which means that we have to pass the name of the row or column which we want to select.**\n"]},{"cell_type":"code","execution_count":9,"id":"77e3d508-1127-4b3e-88dd-0193f2d85500","metadata":{},"outputs":[{"data":{"text/plain":["First Name                 John\n","Last Name                   Doe\n","Location      120 jefferson st.\n","City                  Riverside\n","State                        NJ\n","Area Code                  8075\n","Name: 0, dtype: object"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["# To select the first row\n","df.loc[0]"]},{"cell_type":"code","execution_count":10,"id":"44b2ffff-01a8-4233-a0f2-51148ede9df7","metadata":{},"outputs":[{"data":{"text/plain":["0             John\n","1             Jack\n","2    John \"Da Man\"\n","Name: First Name, dtype: object"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["# To select the 0th,1st and 2nd row of \"First Name\" column only\n","df.loc[[0,1,2], \"First Name\" ]"]},{"cell_type":"markdown","id":"02cc9da6-43e4-4044-a67e-dd957ad6c3f9","metadata":{},"source":["Now, let's see how to use .iloc for selecting rows from our DataFrame.\n","\n","**iloc() : iloc() is a indexed based selecting method which means that we have to pass integer index in the method to select specific row/column.**\n"]},{"cell_type":"code","execution_count":11,"id":"12b62d77-390c-4093-94b4-ddb266ea8c99","metadata":{},"outputs":[{"data":{"text/plain":["0             John\n","1             Jack\n","2    John \"Da Man\"\n","Name: First Name, dtype: object"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["# To select the 0th,1st and 2nd row of \"First Name\" column only\n","df.iloc[[0,1,2], 0]"]},{"cell_type":"markdown","id":"fb189563-4e2c-437f-bab9-e0c79322b441","metadata":{},"source":["For more information please read the [documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html).\n","\n","Let perform some basic transformation in pandas.\n"]},{"cell_type":"markdown","id":"b58ae1ad-82f3-4ece-ba5a-118bd9e5c175","metadata":{},"source":["### Transform Function in Pandas\n","\n","Python’s Transform function returns a self-produced dataframe with transformed values after applying the function specified in its parameter.\n","\n","Let's see how Transform function works.\n"]},{"cell_type":"code","execution_count":12,"id":"d11d8919-8bea-4529-8214-e5955397775e","metadata":{},"outputs":[],"source":["#import library\n","import pandas as pd\n","import numpy as np"]},{"cell_type":"code","execution_count":13,"id":"7b444204-4caa-4376-810e-73b85fa7b054","metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>a</th>\n","      <th>b</th>\n","      <th>c</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>4</td>\n","      <td>5</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>7</td>\n","      <td>8</td>\n","      <td>9</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   a  b  c\n","0  1  2  3\n","1  4  5  6\n","2  7  8  9"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["#creating a dataframe\n","df=pd.DataFrame(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]), columns=['a', 'b', 'c'])\n","df"]},{"cell_type":"markdown","id":"dc07edae-bf85-41dd-84d4-a7315763e879","metadata":{},"source":["Let’s say we want to add 10 to each element in a dataframe:\n"]},{"cell_type":"code","execution_count":17,"id":"905f8e85-9d09-4b92-9feb-03c92d5a158f","metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>a</th>\n","      <th>b</th>\n","      <th>c</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>11</td>\n","      <td>12</td>\n","      <td>13</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>14</td>\n","      <td>15</td>\n","      <td>16</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>17</td>\n","      <td>18</td>\n","      <td>19</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    a   b   c\n","0  11  12  13\n","1  14  15  16\n","2  17  18  19"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["#applying the transform function\n","df = df.transform(func = lambda x : x + 10)\n","df"]},{"cell_type":"markdown","id":"93035b73-80ee-41d6-b145-d188abd53bf4","metadata":{},"source":["Now we will use DataFrame.transform() function to find the square root to each element of the dataframe.\n"]},{"cell_type":"code","execution_count":18,"id":"cc4d4272-7a04-48bc-8502-c97c6c8e89a7","metadata":{},"outputs":[],"source":["result = df.transform(func = ['sqrt'])"]},{"cell_type":"code","execution_count":19,"id":"5aa8a083-bc5f-49cd-8631-05b763327db6","metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead tr th {\n","        text-align: left;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr>\n","      <th></th>\n","      <th>a</th>\n","      <th>b</th>\n","      <th>c</th>\n","    </tr>\n","    <tr>\n","      <th></th>\n","      <th>sqrt</th>\n","      <th>sqrt</th>\n","      <th>sqrt</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3.316625</td>\n","      <td>3.464102</td>\n","      <td>3.605551</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3.741657</td>\n","      <td>3.872983</td>\n","      <td>4.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4.123106</td>\n","      <td>4.242641</td>\n","      <td>4.358899</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          a         b         c\n","       sqrt      sqrt      sqrt\n","0  3.316625  3.464102  3.605551\n","1  3.741657  3.872983  4.000000\n","2  4.123106  4.242641  4.358899"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["result"]},{"cell_type":"markdown","id":"675477e4-0b64-4fc9-a1f8-9ff075332630","metadata":{},"source":["For more information about the **transform()** function  please read the [documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.transform.html).\n"]},{"cell_type":"markdown","id":"d4143ba4-7f5e-4471-ab73-a633710c5a48","metadata":{},"source":["# JSON file Format\n"]},{"cell_type":"markdown","id":"a04b12e6-cc2d-4246-9420-1e8ee2fa5b41","metadata":{},"source":["**JSON (JavaScript Object Notation)** is a lightweight data-interchange format. It is easy for humans to read and write.\n","\n","JSON is built on two structures:\n","\n","1. A collection of name/value pairs. In various languages, this is realized as an object, record, struct, dictionary, hash table, keyed list, or associative array.\n","\n","2. An ordered list of values. In most languages, this is realized as an array, vector, list, or sequence.\n","\n","JSON is a language-independent data format. It was derived from JavaScript, but many modern programming languages include code to generate and parse JSON-format data. It is a very common data format with a diverse range of applications.\n"]},{"cell_type":"markdown","id":"908b96db-92b4-4637-bf6e-34c8c6b72ec8","metadata":{},"source":["The text in JSON is done through quoted string which contains the values in key-value mappings within { }. It is similar to the dictionary in Python.\n","\n"]},{"cell_type":"markdown","id":"958d3c39-95ee-401f-91bc-c9bb96261d13","metadata":{},"source":["Python supports JSON through a built-in package called **json**. To use this feature, we import the json package in Python script.\n"]},{"cell_type":"code","execution_count":null,"id":"92c76b3d-9ed6-483d-8060-a5a0ea82f0f9","metadata":{},"outputs":[],"source":["import json"]},{"cell_type":"markdown","id":"674b2075-7157-48e0-8a35-b8745b26c24f","metadata":{},"source":["# Writing JSON to a File\n","\n","This is usually called **serialization**. It is the process of converting an object into a special format which is suitable for transmitting over the network or storing in file or database.\n","\n","To handle the data flow in a file, the JSON library in Python uses the **dump()** or **dumps()** function to convert the Python objects into their respective JSON object. This makes it easy to write data to files.\n"]},{"cell_type":"code","execution_count":20,"id":"2dbd2d2f-f008-4604-a6a5-598b12e52697","metadata":{},"outputs":[],"source":["import json\n","person = {\n","    'first_name' : 'Mark',\n","    'last_name' : 'abc',\n","    'age' : 27,\n","    'address': {\n","        \"streetAddress\": \"21 2nd Street\",\n","        \"city\": \"New York\",\n","        \"state\": \"NY\",\n","        \"postalCode\": \"10021-3100\"\n","    }\n","}"]},{"cell_type":"markdown","id":"774c4515-da50-43ce-a25a-08f33d781c15","metadata":{},"source":["#### serialization using dump() function\n","\n","**json.dump()** method can be used for writing to JSON file.\n","\n","Syntax: json.dump(dict, file_pointer)\n","\n","Parameters:\n","\n","1. **dictionary** – name of the dictionary which should be converted to JSON object.\n","2. **file pointer** – pointer of the file opened in write or append mode.\n"]},{"cell_type":"code","execution_count":null,"id":"fff2dea2-2360-4c70-bde6-ab3c40a65fa3","metadata":{},"outputs":[],"source":["with open('person.json', 'w') as f:  # writing JSON object\n","    json.dump(person, f)"]},{"cell_type":"markdown","id":"9fad5702-4920-4c6f-8999-2a35127f302d","metadata":{},"source":["#### serialization using dumps() function\n","\n","**json.dumps()** that helps in converting a dictionary to a JSON object.\n","\n","It takes two parameters:\n","1. **dictionary** – name of the dictionary which should be converted to JSON object.\n","2. **indent** – defines the number of units for indentation\n"]},{"cell_type":"code","execution_count":null,"id":"4d0080e1-d298-4742-8482-90e4b56081c7","metadata":{},"outputs":[],"source":["# Serializing json  \n","json_object = json.dumps(person, indent = 4) \n","  \n","# Writing to sample.json \n","with open(\"sample.json\", \"w\") as outfile: \n","    outfile.write(json_object) "]},{"cell_type":"code","execution_count":null,"id":"6eff9840-2be3-4a8e-99b9-5d9a168d51e3","metadata":{},"outputs":[],"source":["print(json_object)"]},{"cell_type":"markdown","id":"17403323-d11d-4a54-a5e8-400be9722cdb","metadata":{},"source":["Our Python objects are now serialized to the file. To deserialize it back to the Python object, we use the load() function.\n"]},{"cell_type":"markdown","id":"25ec7860-251b-482f-bcef-8eb9f88eaf4a","metadata":{},"source":["# Reading JSON to a File\n"]},{"cell_type":"markdown","id":"d585b2f8-724d-4305-8754-240a5be2ada5","metadata":{},"source":["This process is usually called **Deserialization** - it is the reverse of serialization. It converts the special format returned by the serialization back into a usable object.\n","\n","### Using json.load()\n","\n","The JSON package has json.load() function that loads the json content from a json file into a dictionary.\n","\n","It takes one parameter:\n","\n","File pointer: A file pointer that points to a JSON file.\n"]},{"cell_type":"code","execution_count":null,"id":"a8c5faa9-2bc1-4128-9441-db1113655adb","metadata":{},"outputs":[],"source":["import json \n","  \n","# Opening JSON file \n","with open('sample.json', 'r') as openfile: \n","  \n","    # Reading from json file \n","    json_object = json.load(openfile) \n","  \n","print(json_object) \n","print(type(json_object)) "]},{"cell_type":"markdown","id":"b2e77e0c-1589-46d7-835f-6059fb040bcc","metadata":{},"source":["# XLSX file format\n"]},{"cell_type":"markdown","id":"83ea8515-bd73-46a7-ba1b-8bb8ebeaaa78","metadata":{},"source":["**XLSX** is a Microsoft Excel Open XML file format. It is another type of Spreadsheet file format.\n","\n","In XLSX data is organized under the cells and columns in a sheet.\n"]},{"cell_type":"markdown","id":"bfc2a55c-b5d3-4e88-8ed9-3156d3308753","metadata":{},"source":["## Reading the data from XLSX file\n"]},{"cell_type":"markdown","id":"6e3dada9-aa5f-4d12-bab2-a4d817aaa127","metadata":{},"source":["Let’s load the data from XLSX file and define the sheet name. For loading the data you can use the Pandas library in python.\n"]},{"cell_type":"code","execution_count":null,"id":"e2d825ca-9eeb-44e8-b984-56035f031c75","metadata":{},"outputs":[],"source":["import pandas as pd"]},{"cell_type":"code","execution_count":null,"id":"a897aed5-143b-4c79-9499-8254e0be47d9","metadata":{},"outputs":[],"source":["!pip install openpyxl"]},{"cell_type":"code","execution_count":null,"id":"0cf90ec1-aecb-4968-a7be-fa6fb61844bf","metadata":{},"outputs":[],"source":["import urllib.request\n","\n","urllib.request.urlretrieve(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0101EN-SkillsNetwork/labs/Module%205/data/file_example_XLSX_10.xlsx\", \"sample.xlsx\")\n","df = pd.read_excel(\"sample.xlsx\")"]},{"cell_type":"code","execution_count":null,"id":"b35445fe-72cd-4aba-a402-47d3ab56f849","metadata":{},"outputs":[],"source":["df"]},{"cell_type":"markdown","id":"83653392-230e-420f-99e9-86e90caf7f62","metadata":{},"source":["# XML file format\n"]},{"cell_type":"markdown","id":"e2c761c4-ae5c-47b5-8e34-4e4f3aed5965","metadata":{},"source":["**XML is also known as Extensible Markup Language**. As the name suggests, it is a markup language. It has certain rules for encoding data. XML file format is a human-readable and machine-readable file format.\n","\n","Pandas does not include any methods to read and write XML files. Here, we will take a look at how we can use other modules to read data from an XML file, and load it into a Pandas DataFrame.\n"]},{"cell_type":"markdown","id":"61be6d7c-10c8-489a-a2cb-dd391fa66135","metadata":{},"source":["### Writing with xml.etree.ElementTree\n"]},{"cell_type":"markdown","id":"250eb970-704e-448d-8115-5187d123bd54","metadata":{},"source":["The **xml.etree.ElementTree** module comes built-in with Python. It provides functionality for parsing and creating XML documents. ElementTree represents the XML document as a tree. We can move across the document using nodes which are elements and sub-elements of the XML file.\n","\n","For more information please read the [xml.etree.ElementTree](https://docs.python.org/3/library/xml.etree.elementtree.html) documentation.\n"]},{"cell_type":"code","execution_count":null,"id":"098dd310-7e6d-44a6-b107-34091ab10a91","metadata":{},"outputs":[],"source":["import xml.etree.ElementTree as ET\n","\n","# create the file structure\n","employee = ET.Element('employee')\n","details = ET.SubElement(employee, 'details')\n","first = ET.SubElement(details, 'firstname')\n","second = ET.SubElement(details, 'lastname')\n","third = ET.SubElement(details, 'age')\n","first.text = 'Shiv'\n","second.text = 'Mishra'\n","third.text = '23'\n","\n","# create a new XML file with the results\n","mydata1 = ET.ElementTree(employee)\n","# myfile = open(\"items2.xml\", \"wb\")\n","# myfile.write(mydata)\n","with open(\"new_sample.xml\", \"wb\") as files:\n","    mydata1.write(files)"]},{"cell_type":"markdown","id":"39d2dbea-b438-40d3-aad4-0616575d947b","metadata":{},"source":["### Reading with xml.etree.ElementTree\n"]},{"cell_type":"markdown","id":"8a8f9898-5f97-4365-9071-bee201160af6","metadata":{},"source":["Let's have a look at a one way to read XML data and put it in a Pandas DataFrame. You can see the XML file in the Notepad of your local machine.\n"]},{"cell_type":"code","execution_count":21,"id":"7112944a-b613-4b66-a033-f0a21d0147c6","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","\n","  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n","  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n","100  1016  100  1016    0     0    677      0  0:00:01  0:00:01 --:--:--   679\n"]}],"source":["import pandas as pd \n","\n","import xml.etree.ElementTree as etree\n","\n","!curl -o Sample-employee-XML-file.xml https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0101EN-SkillsNetwork/labs/Module%205/data/Sample-employee-XML-file.xml"]},{"cell_type":"markdown","id":"d9753472-9518-400c-9309-06d19ab5a4e8","metadata":{},"source":["You would need to firstly parse an XML file and create a list of columns for data frame, then extract useful information from the XML file and add to a pandas data frame.\n","\n","Here is a sample code that you can use.:\n"]},{"cell_type":"code","execution_count":22,"id":"493cab43-cdac-4dba-9543-65e10652a7ff","metadata":{},"outputs":[{"ename":"AttributeError","evalue":"'DataFrame' object has no attribute 'append'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10504\\3193518958.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mbuilding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"building\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mroom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"room\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mdatatframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatatframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfirstname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlastname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdivision\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuilding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroom\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6292\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6293\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6294\u001b[0m         \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6295\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6296\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'append'"]}],"source":["tree = etree.parse(\"Sample-employee-XML-file.xml\")\n","\n","root = tree.getroot()\n","columns = [\"firstname\", \"lastname\", \"title\", \"division\", \"building\",\"room\"]\n","\n","datatframe = pd.DataFrame(columns = columns)\n","\n","for node in root: \n","\n","    firstname = node.find(\"firstname\").text\n","\n","    lastname = node.find(\"lastname\").text \n","\n","    title = node.find(\"title\").text \n","    \n","    division = node.find(\"division\").text \n","    \n","    building = node.find(\"building\").text\n","    \n","    room = node.find(\"room\").text\n","    \n","    datatframe = datatframe.append(pd.Series([firstname, lastname, title, division, building, room], index = columns), ignore_index = True)"]},{"cell_type":"code","execution_count":null,"id":"4d3b6258-f72c-46cc-b36e-e23e9b5ed378","metadata":{},"outputs":[],"source":["datatframe"]},{"cell_type":"markdown","id":"70f42065-618b-4faf-91c1-b525f3ef3e4e","metadata":{},"source":["### Reading xml  file using pandas.read_xml function\n","\n","We can also read the downloaded xml file using the read_xml function present in the pandas library which returns a Dataframe object.\n","\n","For more information read the <a href=\"https://pandas.pydata.org/pandas-docs/dev/reference/api/pandas.read_xml.html#pandas-read-xml\">pandas.read_xml</a> documentation.\n"]},{"cell_type":"code","execution_count":23,"id":"8c0d05d9-dfe7-456b-9e4d-73d9ad17c09e","metadata":{},"outputs":[{"ename":"ImportError","evalue":"lxml not found, please install or use the etree parser.","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)","Cell \u001b[1;32mIn[23], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Herein xpath we mention the set of xml nodes to be considered for migrating  to the dataframe which in this case is details node under employees.\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_xml\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSample-employee-XML-file.xml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/employees/details\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\xml.py:1160\u001b[0m, in \u001b[0;36mread_xml\u001b[1;34m(path_or_buffer, xpath, namespaces, elems_only, attrs_only, names, dtype, converters, parse_dates, encoding, parser, stylesheet, iterparse, compression, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    888\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    889\u001b[0m \u001b[38;5;124;03mRead XML document into a :class:`~pandas.DataFrame` object.\u001b[39;00m\n\u001b[0;32m    890\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1156\u001b[0m \u001b[38;5;124;03m1      1  <NA>  4.5  False  b 2019-12-31\u001b[39;00m\n\u001b[0;32m   1157\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1158\u001b[0m check_dtype_backend(dtype_backend)\n\u001b[1;32m-> 1160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_parse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1161\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buffer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1162\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1163\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnamespaces\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnamespaces\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1164\u001b[0m \u001b[43m    \u001b[49m\u001b[43melems_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43melems_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1165\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattrs_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1166\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1167\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1168\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconverters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1169\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1170\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1171\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1172\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstylesheet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstylesheet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1173\u001b[0m \u001b[43m    \u001b[49m\u001b[43miterparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miterparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1176\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1177\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\xml.py:830\u001b[0m, in \u001b[0;36m_parse\u001b[1;34m(path_or_buffer, xpath, namespaces, elems_only, attrs_only, names, dtype, converters, parse_dates, encoding, parser, stylesheet, iterparse, compression, storage_options, dtype_backend, **kwargs)\u001b[0m\n\u001b[0;32m    813\u001b[0m         p \u001b[38;5;241m=\u001b[39m _LxmlFrameParser(\n\u001b[0;32m    814\u001b[0m             path_or_buffer,\n\u001b[0;32m    815\u001b[0m             xpath,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    827\u001b[0m             storage_options,\n\u001b[0;32m    828\u001b[0m         )\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 830\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlxml not found, please install or use the etree parser.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m parser \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124metree\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    833\u001b[0m     p \u001b[38;5;241m=\u001b[39m _EtreeFrameParser(\n\u001b[0;32m    834\u001b[0m         path_or_buffer,\n\u001b[0;32m    835\u001b[0m         xpath,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    847\u001b[0m         storage_options,\n\u001b[0;32m    848\u001b[0m     )\n","\u001b[1;31mImportError\u001b[0m: lxml not found, please install or use the etree parser."]}],"source":["# Herein xpath we mention the set of xml nodes to be considered for migrating  to the dataframe which in this case is details node under employees.\n","df=pd.read_xml(\"Sample-employee-XML-file.xml\", xpath=\"/employees/details\") "]},{"cell_type":"markdown","id":"e38ab16b-ef88-46c1-8310-5fd483c4ce22","metadata":{},"source":["### Save Data\n"]},{"cell_type":"markdown","id":"557b8b2d-d02f-460e-b070-6d57f344e3b4","metadata":{},"source":["Correspondingly, Pandas enables us to save the dataset to csv by using the **dataframe.to_csv()** method, you can add the file path and name along with quotation marks in the parentheses.\n","\n","For example, if you would save the dataframe df as **employee.csv** to your local machine, you may use the syntax below:\n"]},{"cell_type":"code","execution_count":null,"id":"7c54d0a0-0d91-4b3f-b533-e1c9d9a8d667","metadata":{},"outputs":[],"source":["datatframe.to_csv(\"employee.csv\", index=False)"]},{"cell_type":"markdown","id":"3357d152-ca8d-4632-8929-848850187e08","metadata":{},"source":[" We can also read and save other file formats, we can use similar functions to **`pd.read_csv()`** and **`df.to_csv()`** for other data formats. The functions are listed in the following table:\n"]},{"cell_type":"markdown","id":"8bbdf867-ce97-4ed4-b417-b7c2902daea5","metadata":{},"source":["<h2>Read/Save Other Data Formats</h2>\n","\n","| Data Formate  | Read           | Save             |\n","| ------------- |:--------------:| ----------------:|\n","| csv           | `pd.read_csv()`  |`df.to_csv()`     |\n","| json          | `pd.read_json()` |`df.to_json()`    |\n","| excel         | `pd.read_excel()`|`df.to_excel()`   |\n","| hdf           | `pd.read_hdf()`  |`df.to_hdf()`     |\n","| sql           | `pd.read_sql()`  |`df.to_sql()`     |\n","| ...           |   ...          |       ...        |\n"]},{"cell_type":"markdown","id":"d95f821f-58b7-49d8-8c05-b9a832d63e8f","metadata":{},"source":["Let's move ahead and perform some **Data Analysis**.\n"]},{"cell_type":"markdown","id":"a10d8a97-8675-4f03-bfc2-d70e362d846d","metadata":{},"source":["# Binary File Format\n","\n","\"Binary\" files are any files where the format isn't made up of readable characters. It contain formatting information that only certain applications or processors can understand. While humans can read text files, binary files must be run on the appropriate software or processor before humans can read them.\n","\n","Binary files can range from image files like JPEGs or GIFs, audio files like MP3s or binary document formats like Word or PDF.\n","\n","Let's see how to read an **Image** file.\n","\n","## Reading the Image file\n","\n","Python supports very powerful tools when it comes to image processing. Let’s see how to process the images using the **PIL** library.\n","\n","PIL is the Python Imaging Library which provides the python interpreter with image editing capabilities.\n"]},{"cell_type":"code","execution_count":24,"id":"d89a92f1-5e92-4c52-9da3-20684777bc61","metadata":{},"outputs":[{"data":{"text/plain":["('dog.jpg', <http.client.HTTPMessage at 0x1657d879160>)"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["# importing PIL \n","from PIL import Image \n","\n","import urllib.request\n","# Downloading dataset\n","urllib.request.urlretrieve(\"https://hips.hearstapps.com/hmg-prod.s3.amazonaws.com/images/dog-puppy-on-garden-royalty-free-image-1586966191.jpg\", \"dog.jpg\")"]},{"cell_type":"code","execution_count":25,"id":"f501cf68-1a7b-4b6b-9951-4ee4b8ccf8fb","metadata":{},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mFailed to interrupt the Kernel. \n","\u001b[1;31mUnable to start Kernel 'Python 3.12.2' due to a timeout waiting for the ports to get used. \n","\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["# Read image \n","img = Image.open('dog.jpg') \n","  \n","# Output Images \n","display(img)"]},{"cell_type":"markdown","id":"466919d8-a27d-46f6-bb03-72f83524f5e5","metadata":{},"source":["# Data Analysis\n"]},{"cell_type":"markdown","id":"34c1fa38-cc46-4c72-bc0e-0f4d9747d6f4","metadata":{},"source":["In this section, you will learn how to approach data acquisition in various ways and obtain necessary insights from a dataset. By the end of this lab, you will successfully load the data into Jupyter Notebook and gain some fundamental insights via the Pandas Library.\n","\n","In our case, the **Diabetes Dataset** is an online source and it is in CSV (comma separated value) format. Let's use this dataset as an example to practice data reading.\n"]},{"cell_type":"markdown","id":"d5fab219-c3b1-454c-870e-3238412b82f1","metadata":{},"source":["## About this Dataset\n","\n","**Context:** This dataset is originally from the **National Institute of Diabetes and Digestive and Kidney Diseases**. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years of age of Pima Indian heritage.\n","\n","**Content:** The datasets consists of several medical predictor variables and one target variable, Outcome. Predictor variables includes the number of pregnancies the patient has had, their BMI, insulin level, age, and so on.\n"]},{"cell_type":"markdown","id":"ab34309f-fb5f-4cba-a370-27e146da155c","metadata":{},"source":["We have 768 rows and 9 columns. The first 8 columns represent the features and the last column represent the target/label.\n"]},{"cell_type":"code","execution_count":1,"id":"261ecf61-554e-4d2c-9409-e1b6951999a5","metadata":{},"outputs":[],"source":["# Import pandas library\n","import pandas as pd"]},{"cell_type":"code","execution_count":2,"id":"1ecd29a9-9a94-4db1-85d1-56a0a170e44d","metadata":{},"outputs":[],"source":["path = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0101EN-SkillsNetwork/labs/Module%205/data/diabetes.csv\"\n","df = pd.read_csv(path)"]},{"cell_type":"markdown","id":"78d2c765-5e82-42ae-b783-2a0709a6bd31","metadata":{},"source":["After reading the dataset, we can use the **dataframe.head(n)** method to check the top n rows of the dataframe, where n is an integer. Contrary to **dataframe.head(n)**, **dataframe.tail(n)** will show you the bottom n rows of the dataframe.\n"]},{"cell_type":"code","execution_count":3,"id":"fe2c67f1-ab95-4ce3-8567-1d712131cfe1","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["The first 5 rows of the dataframe\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Pregnancies</th>\n","      <th>Glucose</th>\n","      <th>BloodPressure</th>\n","      <th>SkinThickness</th>\n","      <th>Insulin</th>\n","      <th>BMI</th>\n","      <th>DiabetesPedigreeFunction</th>\n","      <th>Age</th>\n","      <th>Outcome</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>6</td>\n","      <td>148</td>\n","      <td>72</td>\n","      <td>35</td>\n","      <td>0</td>\n","      <td>33.6</td>\n","      <td>0.627</td>\n","      <td>50</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>85</td>\n","      <td>66</td>\n","      <td>29</td>\n","      <td>0</td>\n","      <td>26.6</td>\n","      <td>0.351</td>\n","      <td>31</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>8</td>\n","      <td>183</td>\n","      <td>64</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>23.3</td>\n","      <td>0.672</td>\n","      <td>32</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>89</td>\n","      <td>66</td>\n","      <td>23</td>\n","      <td>94</td>\n","      <td>28.1</td>\n","      <td>0.167</td>\n","      <td>21</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>137</td>\n","      <td>40</td>\n","      <td>35</td>\n","      <td>168</td>\n","      <td>43.1</td>\n","      <td>2.288</td>\n","      <td>33</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n","0            6      148             72             35        0  33.6   \n","1            1       85             66             29        0  26.6   \n","2            8      183             64              0        0  23.3   \n","3            1       89             66             23       94  28.1   \n","4            0      137             40             35      168  43.1   \n","\n","   DiabetesPedigreeFunction  Age  Outcome  \n","0                     0.627   50        1  \n","1                     0.351   31        0  \n","2                     0.672   32        1  \n","3                     0.167   21        0  \n","4                     2.288   33        1  "]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# show the first 5 rows using dataframe.head() method\n","print(\"The first 5 rows of the dataframe\") \n","df.head(5)"]},{"cell_type":"markdown","id":"3072b3d7-e822-419f-8a91-0c598d34df0f","metadata":{},"source":["To view the dimensions of the dataframe, we use the **`.shape`** parameter.\n"]},{"cell_type":"code","execution_count":4,"id":"3104e4eb-9e6a-4018-abe3-4988fcef596d","metadata":{},"outputs":[{"data":{"text/plain":["(768, 9)"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["df.shape"]},{"cell_type":"markdown","id":"d72f9618-fa49-4501-b762-5aa36e1f2d69","metadata":{},"source":["# Statistical Overview of dataset\n"]},{"cell_type":"code","execution_count":5,"id":"bad250a7-e311-4537-9a9d-c7c5801a2f3f","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 768 entries, 0 to 767\n","Data columns (total 9 columns):\n"," #   Column                    Non-Null Count  Dtype  \n","---  ------                    --------------  -----  \n"," 0   Pregnancies               768 non-null    int64  \n"," 1   Glucose                   768 non-null    int64  \n"," 2   BloodPressure             768 non-null    int64  \n"," 3   SkinThickness             768 non-null    int64  \n"," 4   Insulin                   768 non-null    int64  \n"," 5   BMI                       768 non-null    float64\n"," 6   DiabetesPedigreeFunction  768 non-null    float64\n"," 7   Age                       768 non-null    int64  \n"," 8   Outcome                   768 non-null    int64  \n","dtypes: float64(2), int64(7)\n","memory usage: 54.1 KB\n"]}],"source":["df.info()"]},{"cell_type":"markdown","id":"e5ff4efe-c49e-4dfc-b62d-4086a6f8b989","metadata":{},"source":["This method prints information about a DataFrame including the index dtype and columns, non-null values and memory usage.\n"]},{"cell_type":"code","execution_count":6,"id":"46b95988-bfb2-401a-850c-e234667d0ba6","metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Pregnancies</th>\n","      <th>Glucose</th>\n","      <th>BloodPressure</th>\n","      <th>SkinThickness</th>\n","      <th>Insulin</th>\n","      <th>BMI</th>\n","      <th>DiabetesPedigreeFunction</th>\n","      <th>Age</th>\n","      <th>Outcome</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>768.000000</td>\n","      <td>768.000000</td>\n","      <td>768.000000</td>\n","      <td>768.000000</td>\n","      <td>768.000000</td>\n","      <td>768.000000</td>\n","      <td>768.000000</td>\n","      <td>768.000000</td>\n","      <td>768.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>3.845052</td>\n","      <td>120.894531</td>\n","      <td>69.105469</td>\n","      <td>20.536458</td>\n","      <td>79.799479</td>\n","      <td>31.992578</td>\n","      <td>0.471876</td>\n","      <td>33.240885</td>\n","      <td>0.348958</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>3.369578</td>\n","      <td>31.972618</td>\n","      <td>19.355807</td>\n","      <td>15.952218</td>\n","      <td>115.244002</td>\n","      <td>7.884160</td>\n","      <td>0.331329</td>\n","      <td>11.760232</td>\n","      <td>0.476951</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.078000</td>\n","      <td>21.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>1.000000</td>\n","      <td>99.000000</td>\n","      <td>62.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>27.300000</td>\n","      <td>0.243750</td>\n","      <td>24.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>3.000000</td>\n","      <td>117.000000</td>\n","      <td>72.000000</td>\n","      <td>23.000000</td>\n","      <td>30.500000</td>\n","      <td>32.000000</td>\n","      <td>0.372500</td>\n","      <td>29.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>6.000000</td>\n","      <td>140.250000</td>\n","      <td>80.000000</td>\n","      <td>32.000000</td>\n","      <td>127.250000</td>\n","      <td>36.600000</td>\n","      <td>0.626250</td>\n","      <td>41.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>17.000000</td>\n","      <td>199.000000</td>\n","      <td>122.000000</td>\n","      <td>99.000000</td>\n","      <td>846.000000</td>\n","      <td>67.100000</td>\n","      <td>2.420000</td>\n","      <td>81.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n","count   768.000000  768.000000     768.000000     768.000000  768.000000   \n","mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n","std       3.369578   31.972618      19.355807      15.952218  115.244002   \n","min       0.000000    0.000000       0.000000       0.000000    0.000000   \n","25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n","50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n","75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n","max      17.000000  199.000000     122.000000      99.000000  846.000000   \n","\n","              BMI  DiabetesPedigreeFunction         Age     Outcome  \n","count  768.000000                768.000000  768.000000  768.000000  \n","mean    31.992578                  0.471876   33.240885    0.348958  \n","std      7.884160                  0.331329   11.760232    0.476951  \n","min      0.000000                  0.078000   21.000000    0.000000  \n","25%     27.300000                  0.243750   24.000000    0.000000  \n","50%     32.000000                  0.372500   29.000000    0.000000  \n","75%     36.600000                  0.626250   41.000000    1.000000  \n","max     67.100000                  2.420000   81.000000    1.000000  "]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["df.describe()"]},{"cell_type":"markdown","id":"9843e94e-a979-4803-8a47-c444057eb6c7","metadata":{},"source":["Pandas **describe()** is used to view some basic statistical details like percentile, mean, standard deviation, etc. of a data frame or a series of numeric values. When this method is applied to a series of strings, it returns a different output \n"]},{"cell_type":"markdown","id":"27ea03ee-f468-4138-b12d-dd0a434a7810","metadata":{},"source":["### Identify and handle missing values\n"]},{"cell_type":"markdown","id":"0178abc1-7c53-4150-ae07-c2966ac73804","metadata":{},"source":["We use Python's built-in functions to identify these missing values. There are two methods to detect missing data:\n","\n","\n","**.isnull()**\n","\n","**.notnull()**\n","\n","The output is a boolean value indicating whether the value that is passed into the argument is in fact missing data.\n"]},{"cell_type":"code","execution_count":7,"id":"62ca7a04-09ed-47ea-ad93-03681ebbd1a2","metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Pregnancies</th>\n","      <th>Glucose</th>\n","      <th>BloodPressure</th>\n","      <th>SkinThickness</th>\n","      <th>Insulin</th>\n","      <th>BMI</th>\n","      <th>DiabetesPedigreeFunction</th>\n","      <th>Age</th>\n","      <th>Outcome</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin    BMI  \\\n","0        False    False          False          False    False  False   \n","1        False    False          False          False    False  False   \n","2        False    False          False          False    False  False   \n","3        False    False          False          False    False  False   \n","4        False    False          False          False    False  False   \n","\n","   DiabetesPedigreeFunction    Age  Outcome  \n","0                     False  False    False  \n","1                     False  False    False  \n","2                     False  False    False  \n","3                     False  False    False  \n","4                     False  False    False  "]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["missing_data = df.isnull()\n","missing_data.head(5)"]},{"cell_type":"markdown","id":"6203eb91-9d05-40a3-bd48-80d6e1867900","metadata":{},"source":["\"True\" stands for missing value, while \"False\" stands for not missing value.\n"]},{"cell_type":"markdown","id":"87630612-3440-4522-b528-060fa323bbba","metadata":{},"source":["<h4>Count missing values in each column</h4>\n","<p>\n","Using a for loop in Python, we can quickly figure out the number of missing values in each column. As mentioned above, \"True\" represents a missing value, \"False\"  means the value is present in the dataset.  In the body of the for loop the method \".value_counts()\"  counts the number of \"True\" values. \n","</p>\n"]},{"cell_type":"code","execution_count":8,"id":"f35de112-f470-4035-a473-85b590607935","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Pregnancies\n","Pregnancies\n","False    768\n","Name: count, dtype: int64\n","\n","Glucose\n","Glucose\n","False    768\n","Name: count, dtype: int64\n","\n","BloodPressure\n","BloodPressure\n","False    768\n","Name: count, dtype: int64\n","\n","SkinThickness\n","SkinThickness\n","False    768\n","Name: count, dtype: int64\n","\n","Insulin\n","Insulin\n","False    768\n","Name: count, dtype: int64\n","\n","BMI\n","BMI\n","False    768\n","Name: count, dtype: int64\n","\n","DiabetesPedigreeFunction\n","DiabetesPedigreeFunction\n","False    768\n","Name: count, dtype: int64\n","\n","Age\n","Age\n","False    768\n","Name: count, dtype: int64\n","\n","Outcome\n","Outcome\n","False    768\n","Name: count, dtype: int64\n","\n"]}],"source":["for column in missing_data.columns.values.tolist():\n","    print(column)\n","    print (missing_data[column].value_counts())\n","    print(\"\")    "]},{"cell_type":"markdown","id":"64b5f7a5-2b60-436b-b5e4-777ec1a226d8","metadata":{},"source":["As you can see above, there is no missing values in the dataset.\n"]},{"cell_type":"markdown","id":"244a6c88-2da9-4ef4-bdf5-a03deb525ea0","metadata":{},"source":["<h3 id=\"correct_data_format\">Correct data format</h3>\n","\n","<p>Check all data is in the correct format (int, float, text or other).</p>\n","\n","In Pandas, we use \n","<p><b>.dtype()</b> to check the data type</p>\n","<p><b>.astype()</b> to change the data type</p>\n","\n","Numerical variables should have type **'float'** or **'int'**.\n"]},{"cell_type":"code","execution_count":9,"id":"ad8734fd-d833-4ff7-bb28-9ec7a43a7191","metadata":{},"outputs":[{"data":{"text/plain":["Pregnancies                   int64\n","Glucose                       int64\n","BloodPressure                 int64\n","SkinThickness                 int64\n","Insulin                       int64\n","BMI                         float64\n","DiabetesPedigreeFunction    float64\n","Age                           int64\n","Outcome                       int64\n","dtype: object"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["df.dtypes"]},{"cell_type":"markdown","id":"21ade1d9-429d-4758-9e60-1f08524158c1","metadata":{},"source":["As we can see above, All columns have the correct data type.\n"]},{"cell_type":"markdown","id":"e84e5e90-dd78-4c0a-8d3e-73dc50f7215d","metadata":{},"source":["# Visualization\n"]},{"cell_type":"markdown","id":"7b04ff04-f4ff-4e2d-99aa-0e64bcc6886e","metadata":{},"source":["**Visualization** is one of the best way to get insights from the dataset. **Seaborn** and **Matplotlib** are two of Python's most powerful visualization libraries.\n"]},{"cell_type":"code","execution_count":1,"id":"1e2f704a-e4d1-4a8c-8863-6d37a07b191f","metadata":{},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'seaborn'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# import libraries\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"]}],"source":["# import libraries\n","import matplotlib.pyplot as plt\n","import seaborn as sns"]},{"cell_type":"code","execution_count":null,"id":"5a0696bf-6540-4867-a617-99c8a6952b7c","metadata":{},"outputs":[],"source":["labels= 'Not Diabetic','Diabetic'\n","plt.pie(df['Outcome'].value_counts(),labels=labels,autopct='%0.02f%%')\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","id":"58360b94-7d33-4115-ae7b-e02d3f211edd","metadata":{},"source":["As you can see above, 65.10% females are Not Diabetic and 34.90% are Diabetic.\n"]},{"cell_type":"markdown","id":"b0894cd1-8057-4864-910a-a8c73403e070","metadata":{},"source":["# Thank you for completing this Notebook\n"]},{"cell_type":"markdown","id":"91274a5a-8911-4d39-acb2-180effe9370a","metadata":{},"source":["## Change Log\n","\n","\n","|  Date (YYYY-MM-DD) |  Version | Changed By  |  Change Description |\n","|---|---|---|---|\n","| 2022-01-25 | 0.1 | Lakshmi Holla| added read_xml |\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":4}
